{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import spacy \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "friends = pd.read_csv(\"friends_quotes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_characters = [\"Monica\", \"Joey\", \"Phoebe\", \"Ross\", \"Chandler\", \"Rachel\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monica</td>\n",
       "      <td>There's nothing to tell! He's just some guy I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joey</td>\n",
       "      <td>C'mon, you're going out with the guy! There's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>All right Joey, be nice. So does he have a hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phoebe</td>\n",
       "      <td>Wait, does he eat chalk?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phoebe</td>\n",
       "      <td>Just, 'cause, I don't want her to go through w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45477</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>Oh, it's gonna be okay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45478</th>\n",
       "      <td>Rachel</td>\n",
       "      <td>(crying) Do you guys have to go to the new hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45479</th>\n",
       "      <td>Monica</td>\n",
       "      <td>We got some time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45480</th>\n",
       "      <td>Rachel</td>\n",
       "      <td>Okay, should we get some coffee?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45481</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>Sure. Where?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45482 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                                              quote\n",
       "0        Monica  There's nothing to tell! He's just some guy I ...\n",
       "1          Joey  C'mon, you're going out with the guy! There's ...\n",
       "2      Chandler  All right Joey, be nice. So does he have a hum...\n",
       "3        Phoebe                           Wait, does he eat chalk?\n",
       "4        Phoebe  Just, 'cause, I don't want her to go through w...\n",
       "...         ...                                                ...\n",
       "45477  Chandler                            Oh, it's gonna be okay.\n",
       "45478    Rachel  (crying) Do you guys have to go to the new hou...\n",
       "45479    Monica                                  We got some time.\n",
       "45480    Rachel                   Okay, should we get some coffee?\n",
       "45481  Chandler                                       Sure. Where?\n",
       "\n",
       "[45482 rows x 2 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset= friends[friends.author.isin(main_characters)].drop(columns=['episode_number', 'episode_title', \"quote_order\", \"season\"]).reset_index(drop = True)\n",
    "dataset #dataset para trabajar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rachel      8318\n",
       "Ross        8088\n",
       "Monica      7516\n",
       "Chandler    7488\n",
       "Joey        7373\n",
       "Phoebe      6699\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"author\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive_bayes (1st trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code https://www.geeksforgeeks.org/\n",
    "\n",
    "corpus = []\n",
    "  \n",
    "for i in range(0, 45482):\n",
    "    text = re.sub('[^a-zA-Z]', '', dataset['quote'][i])\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    ps = PorterStemmer()\n",
    "    text = ''.join(text)\n",
    "    corpus.append(text)\n",
    "  \n",
    "# creating bag of words model\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "  \n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = dataset.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  59,   25,   12, 1720,   14,    8],\n",
       "       [  13,   54,   11, 1708,   20,    8],\n",
       "       [  13,   21,   53, 1766,   16,    9],\n",
       "       [   8,   22,   16, 1599,   13,    6],\n",
       "       [   9,   25,   31, 1999,   59,   11],\n",
       "       [  12,   28,   25, 1887,   23,   68]], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the data set into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "           X, y, test_size = 0.25, random_state = 0)\n",
    "# fitting naive bayes to the training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "  \n",
    "classifier = GaussianNB();\n",
    "classifier.fit(X_train, y_train)\n",
    "  \n",
    "# predicting test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "  \n",
    "# making the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rachel      2134\n",
       "Ross        2043\n",
       "Monica      1878\n",
       "Chandler    1838\n",
       "Joey        1814\n",
       "Phoebe      1664\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phoebe      10679\n",
       "Joey          175\n",
       "Monica        148\n",
       "Rachel        145\n",
       "Chandler      114\n",
       "Ross          110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive_bayes (2nd trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemSentence(df):\n",
    "    sentence_words = nltk.word_tokenize(df)\n",
    "    lem_sentence=[]\n",
    "    for word in sentence_words:\n",
    "        lem_sentence.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        lem_sentence.append(\" \")\n",
    "        \n",
    "    return \"\".join(lem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "englishStemmer=SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "def stemSentence(df):\n",
    "    token_words=word_tokenize(df)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(englishStemmer.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monica</td>\n",
       "      <td>There's nothing to tell! He's just some guy I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joey</td>\n",
       "      <td>C'mon, you're going out with the guy! There's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>All right Joey, be nice. So does he have a hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phoebe</td>\n",
       "      <td>Wait, does he eat chalk?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phoebe</td>\n",
       "      <td>Just, 'cause, I don't want her to go through w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45477</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>Oh, it's gonna be okay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45478</th>\n",
       "      <td>Rachel</td>\n",
       "      <td>(crying) Do you guys have to go to the new hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45479</th>\n",
       "      <td>Monica</td>\n",
       "      <td>We got some time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45480</th>\n",
       "      <td>Rachel</td>\n",
       "      <td>Okay, should we get some coffee?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45481</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>Sure. Where?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45482 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                                              quote\n",
       "0        Monica  There's nothing to tell! He's just some guy I ...\n",
       "1          Joey  C'mon, you're going out with the guy! There's ...\n",
       "2      Chandler  All right Joey, be nice. So does he have a hum...\n",
       "3        Phoebe                           Wait, does he eat chalk?\n",
       "4        Phoebe  Just, 'cause, I don't want her to go through w...\n",
       "...         ...                                                ...\n",
       "45477  Chandler                            Oh, it's gonna be okay.\n",
       "45478    Rachel  (crying) Do you guys have to go to the new hou...\n",
       "45479    Monica                                  We got some time.\n",
       "45480    Rachel                   Okay, should we get some coffee?\n",
       "45481  Chandler                                       Sure. Where?\n",
       "\n",
       "[45482 rows x 2 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"quote\"] = dataset[\"quote\"].str.replace(\"\\(([^)]+)\\)\",\"\").str.lower().str.replace(\"[^a-zA-Z ]\",\"\").apply(lemSentence).apply(stemSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df=0.005, max_df=0.95, max_features = 1500 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(dataset[\"quote\"]).toarray() \n",
    "y = dataset.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[391, 376, 207, 229, 469, 166],\n",
       "       [265, 484, 193, 243, 465, 164],\n",
       "       [280, 327, 283, 290, 534, 164],\n",
       "       [237, 293, 207, 312, 479, 136],\n",
       "       [291, 334, 237, 289, 818, 165],\n",
       "       [309, 404, 213, 257, 568, 292]], dtype=int64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "           X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "classifier = GaussianNB();\n",
    "classifier.fit(X_train, y_train)\n",
    "  \n",
    "y_pred = classifier.predict(X_test)\n",
    "  \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rachel      3333\n",
       "Joey        2218\n",
       "Chandler    1773\n",
       "Phoebe      1620\n",
       "Monica      1340\n",
       "Ross        1087\n",
       "dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rachel      2134\n",
       "Ross        2043\n",
       "Monica      1878\n",
       "Chandler    1838\n",
       "Joey        1814\n",
       "Phoebe      1664\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decison Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "           X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.22108873450004396\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(max_iter = 10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
